<!DOCTYPE html>
<html>
<head>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@0.13.0"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js" integrity="sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8=" crossorigin="anonymous"></script>
    <script src="scripts/socket.io.js"></script>

    <style>
        html, body {
            background: #000;
        }
        #wrapper {
            text-align: center;
            margin: 10px auto;
        }

        #overlay {
            width: 550px;
        }

        #output_image {
            width: 550px;
        }

        #status {
            color: #FFF;
        }

        #video {
            position: absolute;
            top: calc(50% - 180px);
            left: calc(50% - 250px);
        }

        #canvas {
            position: absolute;
            top: calc(50% - 180px);
            left: calc(50% - 250px);
            z-index: 2;
        }
    </style>
</head>

<body>
    <center style="padding:10px; margin:5px">
        <h4>
            <span id="status">Loading...</span>
        </h4>
    </center>

        <center><span id="original_video"></span></center>
        <video id='video' width="500px"></video>

        <canvas id="canvas" src="" />
</body>
<script>
    // check using phone or not
    if (/Android|webOS|iPhone|iPod|BlackBerry/i.test(navigator.userAgent)) {
        alert('This website does not support running on mobile devices.');
        history.back();
    }

    // check using chrome
    if (!window.chrome) {
        if (confirm('This website only works in Chrome.')) {
            closewin();
        } else {
            history.back();
        }
    }

    var constraints = {
        video: true
    };

    var $body = document.querySelector('body');
    var emotion_labels = ["angry", "disgust", "fear", "happy", "sad", "surprise", "neutral"];
    var emotion_mood_specification = [0.0, 0.2, 0.4, 1.0, 0.5, 0.8, 0.6];
    var emotion_colors = ["#ff0000", "#00a800", "#ff4fc1", "#ffe100", "#306eff", "#ff9d00", "#7c7c7c"];
    var offset_x = 15;
    var offset_y = 40;
        
    var socket = io('http://127.0.0.1:8081');

    loadModel('models/mobilenetv1_models/model.json')

    async function createModel(path) {
        let model_tmp = await tf.loadModel(path)
        return model_tmp
    }


    function createVideoElement() {
        let $video = document.createElement('video')
        $video.style.maxWidth = '100vw'
        $video.style.width = '100vw'
        $video.style.maxHeight = '0vh'
        $body.appendChild($video)
        return $video
    }

    function handleError(error) {
        if (error.name === 'DevicesNotFoundError') {
            alert('No camera detected. <br> Do you have any camera connected?');
        } else if (error.name === 'NotAllowedError') {
            alert('You have to allow camera access in order to run this experiment.');
        } else if (navigator.userAgent.indexOf('Chrome') > -1) {
            alert('Error. <br> Enable experimental features on chrome://flags/#enable-experimental-web-platform-features');
        } else {
            alert('Error. <br> Does your browser supports FaceDetector API?');
        }
        console.error(error)
    }

    function createCanvas(video) {
        const canvas = document.getElementById('canvas')
        const videoCompStyle = window.getComputedStyle(video)
        canvas.width = videoCompStyle.width.replace('px', '')
        canvas.height = videoCompStyle.height.replace('px', '')
        document.querySelector('body').appendChild(canvas)

        return canvas
    }

    function createDrawFunction() {
        const faceDetector = new window.FaceDetector({
            fastMode: true
        })

        let isDetectingFaces = false
        let faces = []
        let hideTimeout

        return async function draw(canvas, video) {
            window.requestAnimationFrame(() => draw(canvas, video))
            const context = canvas.getContext('2d')
            const videoCompStyle = window.getComputedStyle(video)
            const videoWidth = videoCompStyle.width.replace('px', '')
            const videoHeight = videoCompStyle.height.replace('px', '')
            context.drawImage(video, 0, 0, videoWidth, videoHeight)

            let totalMood = 0.0;

            if (faces.length) {
                let ctx = context;

                ctx.lineWidth = 4;
                ctx.font = "20px Arial"
                ctx.fillText('Result', 0, 0);
                for (var i = 0; i < faces.length; i++) {
                    ctx.beginPath();
                    var item = faces[i].boundingBox;
                    let s_x = Math.floor(item.x - offset_x / 2);
                    let s_y = Math.floor(item.y - offset_y / 2);
                    let s_w = Math.floor(item.width + offset_x);
                    let s_h = Math.floor(item.height + offset_y);

                    let cT = ctx.getImageData(s_x, s_y, s_w, s_h);
                    cT = preprocess(cT);
                    z = model.predict(cT)

                    let index = z.argMax(1).dataSync()[0]
                    let label = emotion_labels[index];

                    totalMood += emotion_mood_specification[index];

                    ctx.strokeStyle = emotion_colors[index];
                    ctx.rect(s_x, s_y, s_w, s_h);
                    ctx.stroke();
                    ctx.fillStyle = emotion_colors[index];
                    ctx.fillText(label, s_x, s_y);
                    ctx.closePath();
                }
            }

            if (isDetectingFaces) {
                return
            }

            isDetectingFaces = true
            faces = await faceDetector.detect(canvas)
            isDetectingFaces = false
            var status = document.getElementById('status');
            status.innerHTML = faces.length + " people detected";

            if (faces.length > 0) {
                const mood = totalMood / faces.length;

                socket.emit('message', {
                    address: "/crowd_size",
                    args: [{
                        value: Math.min(faces.length, 10) / 10
                    }]
                });

                socket.emit('message', {
                    address: "/mood",
                    args: [{
                        value: mood
                    }]
                });
            }
        }
    }

    function preprocess(imgData) {
        return tf.tidy(() => {
            let tensor = tf.fromPixels(imgData).toFloat();

            tensor = tensor.resizeBilinear([100, 100])

            tensor = tf.cast(tensor, 'float32')
            const offset = tf.scalar(255.0);

            // Normalize the image 
            const normalized = tensor.div(offset);
            
            // Add a dimension to get a batch shape 
            const batched = normalized.expandDims(0)
            return batched
        })
    }


    function playCameraOnVideo(video) {
        return navigator.mediaDevices.getUserMedia({
                video: {
                    facingMode: 'user',
                    frameRate: 2
                },
                audio: false
            })
            .then(srcObject => video.srcObject = srcObject)
            .then(() => video.play())
    }

    async function main(video) {
        const video_canvas = createCanvas(video)
        const draw = createDrawFunction()
        draw(video_canvas, video)
    }

    function startVideo() {
        var status = document.getElementById('status');
        status.innerHTML = "Loading... ";

        playCameraOnVideo(video)
            .then(() => main(video))
            .catch(handleError)

        socket.on('connect', function() {
            // sends to socket.io server the host/port of oscServer
            // and oscClient
            socket.emit('config',
                {
                    server: {
                        port: 3333,
                        host: '127.0.0.1'
                    },
                    client: {
                        port: 3335,
                        host: '127.0.0.1'
                    }
                }
            );
        });
    }


    // load models
    async function loadModel(path) {
        var status = document.getElementById('status');
        model = await createModel(path)
        startVideo();
    }
</script>

</html>